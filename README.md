# Beacons Indoor

## Abstract
Due to the poor development of indoor location tracking using WIFI signals, this project implements beacons to track real-time indoor location of an Android mobile device with trilateration and fingerprinting. A real-time formula converting beacon signal strengths to distances is generated in each room to account for noise and improve accuracy. All calculations are completed using Android Studio, Gimbal beacons, Gimbal server, and two external libraries. The location data will be useful to Phillips Collection Museum in making better decisions on arrangements such as generating popular visitor routes, developing guiding and recommendation apps, or altering artistic preferences, etc.

## Project Specification

This project provides an approach to collect museum visitors’ data using beacons. It implements Gimbal server methods to collect RSSI values representing the signal strengths of beacons received from a mobile device, creates real-time formula to convert RSSI values to distances between the beacons and the mobile device and produces real-time coordinates of the mobile device using trilateration on distances from three beacons in the same room. I use Gaussian distribution model with three parameters as input to the external library apache commons: math to generate the real-time Gaussian formula. Then the RSSI values are converted to distances using the formula that will only be implemented in the current room and furthermore passed into the second external library that helps create a data point with non-linear least square method, which is the kernel of trilateration. Later, a graph is produced to track all the generated coordinates with regard to time frames. The challenges of this project mainly involve determining a model for the real-time formula, how the formula will be created and how trilateration will be performed. 

This project mimics a user login interface with a sign-in button that when run uses my personal account. It is to demonstrate that a user should be able to log into their own account so that each visitor’s data don’t collide with each other. To make the demonstration application easier, the “automatic” button on the top right corner will log into my own account, start Gimbal service and automatically scan for beacons continuously. This marks the start of the program. An alternative approach is to tap the pen-like button that simulates login (which is actually to login to my Google account) and the “scan” button that starts Gimbal service. A message will appear to show that the Gimbal service has been started. Then the “automatic” button still needs to be tapped to enable continuous scanning, which is the actual condition in user app since we don’t ask users to wait too long.

Fingerprinting must be implemented manually at the entrance of the museum by first tapping the target test beacon in the scanned beacon list and then tapping the “finger print”. A spot will be ideally created with three to four concentric circles for fingerprinting purpose. The mobile device needs to be placed first at the centre, and then gradually at the verge of each circle with specified radii representing the respective distances from a test beacon (for fingerprinting purpose only) placed at the centre. The demonstration app scans three times for each distance (at 0m, 0.5m and 1m) and uses the average value of three values for each distance. User will need to tap on the “0m”, “0.5m” and “1m” buttons to check the progress of fingerprinting. Once done, user will tap the appeared “Gaussian Estimate” button. In the reality there can be more than three distance points that will furthermore increase the accuracy of the generated formula. Yet this should be only possible when the scanning time has been controlled down to a reasonable number. The three groups of distance and RSSI values will be passed into the apache library function to generate a formula based on the Gaussian distribution model. The formula is assumed to be only relatively accurate in the room where we accomplish the fingerprinting. As soon as the user carrying the mobile device leaves the room, a new formula will be created automatically using three new data groups. The details of how to determine these data groups will be specified later.

Since the app stores the distances in time in each Beacon object, two maps are created to gather data from all three beacons in the same room and establish a timeline of data, the first map being beacon ids in timeframe and the second map being distances in timeframe. The reason for this design will be described later. After a timeline of distances has been created, the data points, along with the pre-defined beacon coordinates, are passed into the second external library function which then returns  data points that are the estimated coordinates of the mobile device. This is executed when a list of distances in time is shown above the “Timeline Estimate” button which should be tapped later to calculate the coordinates. A map is used to store the coordinates in time upon success. Then user can view the visual results by tapping the “Graph Display” button which will plot the coordinates on an XY-coordinate system with line segments showing the track.


